[
    {
        "thought": "Directly reason with problem as input and output the reasoning results",
        "name": "IO",
        "module type": "reasoning",
        "code": "class ReasoningIO(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = '''Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{memory}\nHere is the task:\n{task_description}'''\n        prompt = prompt.format(task_description=task_description, examples=examples, memory=self.memory_cache)\n        reasoning_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        \n        return reasoning_result\n    ",
        "performance": 0.56
    },
    {
        "thought": "By encouraging the LLM to think step by step rather than directly outputting an answer, chain-of-thought reasoning enables complex problem-solving through intermediate steps. This practice improves the model's ability to handle tasks that require deeper reasoning and provides insight into its decision-making process.",
        "name": "COT",
        "module type": "reasoning",
        "code": "class ReasoningCOT(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = '''Solve the task step by step. Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{memory}\nHere is the task:\n{task_description}'''\n        prompt = prompt.format(task_description=task_description, examples=examples, memory=self.memory_cache)\n        reasoning_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        return reasoning_result\n    ",
        "performance": 0.52
    },
    {
        "thought": "While an LLM can arrive at the correct answer, its reasoning may vary. By repeatedly asking the same question with high temperature settings, we can generate different reasoning paths. We then combine multiple answers from these Chain-of-Thought (CoT) agents to produce a more accurate final answer through ensembling.",
        "name": "COTSC",
        "module type": "reasoning",
        "code": "class ReasoningCOTSC(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = '''Solve the task step by step. Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{memory}\nHere is the task:\n{task_description}'''\n        prompt = prompt.format(task_description=task_description, examples=examples, memory=self.memory_cache)\n        reasoning_results = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'], n=5)\n        string_counts = Counter(reasoning_results)\n        reasoning_result = string_counts.most_common(1)[0][0]\n        return reasoning_result\n    ",
        "performance": 0.48
    },
    {
        "thought": "Generalize over 'Chain-of-Thought', by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices",
        "name": "TOT",
        "module type": "reasoning",
        "code": "class ReasoningTOT(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = '''Solve the task step by step. Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{memory}\nHere is the task:\n{task_description}'''\n        prompt = prompt.format(task_description=task_description, examples=examples, memory=self.memory_cache)\n        reasoning_results = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'], n=3)\n        reasoning_result = self.get_votes(task_description, reasoning_results, examples)\n        return reasoning_result\n    def get_votes(self, task_description, reasoning_results, examples):\n        if 'think'  in reasoning_results[0].lower():\n            return reasoning_results[0]\n        prompt = '''Given the reasoning process for two completed tasks and one ongoing task, and several answers for the next step, decide which answer best follows the reasoning process for example command format. Output \"The best answer is {{s}}\", where s is the integer id chosen.\nHere are some examples.\n{examples}\nHere is the task:\n{task_description}\n\n'''     \n        prompt = prompt.format(task_description=task_description, examples=examples)\n        for i, y in enumerate(reasoning_results, 1):\n            prompt += f'Answer {i}:\n{y}\n'\n        vote_outputs = llm_response(prompt=prompt, model=self.llm_type, temperature=0.7, n=5)\n        vote_results = [0] * len(reasoning_results)\n        for vote_output in vote_outputs:\n            pattern = r\".*best answer is .*(\\d+).*\"\n            match = re.match(pattern, vote_output, re.DOTALL)\n            if match:\n                vote = int(match.groups()[0]) - 1\n                if vote in range(len(reasoning_results)):\n                    vote_results[vote] += 1\n            else:\n                print(f'vote no match: {[vote_output]}')\n        ids = list(range(len(reasoning_results)))\n        select_id = sorted(ids, key=lambda x: vote_results[x], reverse=True)[0]\n        return reasoning_results[select_id]\n    ",
        "performance": 0.58
    },
    {
        "thought": "To enhance its performance, an LLM can iteratively improve its answer based on feedback. By reflecting on its previous attempts and incorporating feedback, the model can refine its reasoning and provide a more accurate solution.",
        "name": "SelfRefine",
        "module type": "reasoning",
        "code": "class ReasoningSelfRefine(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = '''Solve the task step by step. Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{memory}\nHere is the task:\n{task_description}'''\n        prompt = prompt.format(task_description=task_description, examples=examples, memory=self.memory_cache)\n        reasoning_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        reasoning_result = self.refine(reasoning_result)\n        return reasoning_result\n    def refine(self, reasoning_result):\n        if 'think' in reasoning_result:\n            return reasoning_result\n        prompt = f'''You need to check that the syntactic structure of the step meets the requirements.\nrequirements: '1. take a from b 2. go to a 3. : open a 4. put a in/on b, end. 5. clean a with b, end. 6. heat a with b, end. 7. cool a with b, end. 8. use a, end.', where 'a' and 'b' are variable.\nexamples:\ntake pencil 1 from desk 2   correct\ntake potato 1 with fridge 1 error, The preposition with take is from. revised: take potato 1 from bridge 1\ngo to cabinet 3   correct\ngo to countertop 2 and check   error, go to countertop 2 is the complete instruction. revised: go to countertop 2\nopen fridge 1 and take potato 2   error, open fridge 1 is the complete instruction. revised: open fridge 1\nopen safe 2   correct\nput mug 2 in desk 1, end   error, The preposition with put is in/on. revised: put mug 2 in/on desk 1, end\nput watch 1 in/on safe 1, end   correct\nclean soapbar 1 with sinkbasin 1   error, Add \"end\" to the clean statement. revised: clean soapbar 1 with sinkbasin 1, end\nclean lettuce 4 with sinkbasin 1, end   correct\nheat egg 2 with microwave 1, end   correct\nheat bread 1 with stoveburner 1, end   error, microwave is what you use to heat. revised: heat bread 1 with microwave 1, end\ncool potato 2 with fridge 1, end   correct\ncool pan 1, end   error,  bridge is whta you ues to cool. revised: cool pan 1 with bridge 1, end\nuse desklamp 3 to check statue 2   error, use desklamp3 is the complete instruction. revised: use desklamp 3, end\nuse desklamp 2, end   correct\nJust focus on syntactic structure.\nstep: {reasoning_result}\nYou can only output in two formats:\n\"correct\" or \"error, revised: your step\"\n'''     \n        feedback_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.0)\n        if 'correct' in feedback_result.lower():\n            if ' in ' in reasoning_result:\n                reasoning_result = reasoning_result.replace(' in ', ' in/on ')\n            elif ' on ' in reasoning_result:\n                reasoning_result = reasoning_result.replace(' on ', ' in/on ')\n            return reasoning_result.replace('.', '')\n        else:\n            if ' in ' in feedback_result:\n                feedback_result = feedback_result.replace(' in ', ' in/on ')\n            elif ' on ' in feedback_result:\n                feedback_result = feedback_result.replace(' on ', ' in/on ')\n            return feedback_result.split(':')[-1].replace('.', '').strip()\n    ",
        "performance": 0.78
    },
    {
        "thought": "Role-playing can better guide large language models to solve specific domain problems",
        "name": "DILU",
        "module type": "reasoning",
        "code": "class ReasoningDILU(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        prompt = [\n            {\n                \"role\": \"system\",\n                \"content\": '''You are ChatGPT, a large language model trained by OpenAI. Now you act as a mature domestic robot, who can give accurate and correct instruction in interacting with a household. You will be given a detailed description of the scenario of current frame along with your history of previous decisions. \n'''\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f'''Above messages are some examples of how you make a step successfully in the past. Those scenarios are similar to the current scenario. You should refer to those examples to make a step for the current scenario. Your instructions must follow the examples.\nHere are two examples.\n{examples}{self.memory_cache}\nHere is the task:\n{task_description}'''\n            }\n        ]\n        reasoning_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        return reasoning_result\n    ",
        "performance": 0.6
    },
    {
        "thought": "Let LLM first think about the principles involved in solving this task which could be helpful. By understanding the underlying principles, the model can better reason through the problem and provide a more accurate solution.",
        "name": "StepBack",
        "module type": "reasoning",
        "code": "class ReasoningStepBack(ReasoningBase):\n    def __call__(self, task_description: str, feedback :str= ''):\n        examples, task_description = self.process_task_description(task_description)\n        if task_description.split('Your')[-1].count('>') == 1:\n            self.principle = self.stepback(task_description)\n            \n        prompt = f'''Solve the task step by step. Interact with a household to solve a task. Your instructions must follow the examples.\nHere are some examples.\n{examples}{self.memory_cache}{self.principle}\nHere is the task:\n{task_description}'''\n        reasoning_result = llm_response(prompt=prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        return reasoning_result\n    def stepback(self, task_description):\n        last_index = task_description.rfind('>')\n        task_description = task_description[:last_index]\n        stepback_prompt = f'''What common sense, instruction structure is involved in solving this task?\n{task_description}'''\n        principle = llm_response(prompt=stepback_prompt, model=self.llm_type, temperature=0.1, stop_strs=['\n'])\n        return principle\n    ",
        "performance": 0.56
    }
]